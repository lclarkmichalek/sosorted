name: Benchmark

on:
  pull_request:
    branches: ['**']

permissions:
  contents: read
  pull-requests: write

jobs:
  bench-compare:
    name: Statistical Benchmark Comparison
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout sources
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for git ref comparison

      - name: Install nightly toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: nightly-2026-01-05

      - name: Build bench-compare tool
        run: cargo build --release -p bench-compare

      - name: Run benchmark comparison
        id: bench-compare
        run: |
          set +e  # Don't exit on error
          ./target/release/bench-compare \
            --baseline ${{ github.event.pull_request.base.sha }} \
            --test ${{ github.event.pull_request.head.sha }} \
            --output html \
            --html-output benchmark-report.html \
            --sample-size 50 \
            --keep-binaries
          EXIT_CODE=$?
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0  # Always succeed so we can upload artifacts

      - name: Upload HTML Report
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-report
          path: benchmark-report.html
          retention-days: 30

      - name: Upload Criterion Reports (Baseline)
        uses: actions/upload-artifact@v4
        with:
          name: criterion-baseline
          path: target/bench-compare-baseline/criterion/
          retention-days: 30
          if-no-files-found: ignore

      - name: Upload Criterion Reports (Test)
        uses: actions/upload-artifact@v4
        with:
          name: criterion-test
          path: target/bench-compare-test/criterion/
          retention-days: 30
          if-no-files-found: ignore

      - name: Generate summary
        run: |
          echo "## Benchmark Comparison Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.bench-compare.outputs.exit_code }}" == "1" ]; then
            echo "‚ö†Ô∏è **Regressions detected!** See the HTML report for details." >> $GITHUB_STEP_SUMMARY
          else
            echo "‚úÖ **No regressions detected.**" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìä [Download HTML Report](../artifacts)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Baseline:** \`${{ github.event.pull_request.base.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Test:** \`${{ github.event.pull_request.head.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Sample size:** 50" >> $GITHUB_STEP_SUMMARY
          echo "- **Significance level:** 0.05" >> $GITHUB_STEP_SUMMARY
          echo "- **Effect threshold:** 2.0%" >> $GITHUB_STEP_SUMMARY

      - name: Post comment with results
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ## Statistical Benchmark Comparison

            ${{ steps.bench-compare.outputs.exit_code == '1' && '‚ö†Ô∏è **Regressions detected!**' || '‚úÖ **No regressions detected.**' }}

            üìä **[View Detailed HTML Report](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)**

            | Baseline | Test |
            |----------|------|
            | `${{ github.event.pull_request.base.sha }}` | `${{ github.event.pull_request.head.sha }}` |

            <details>
            <summary>Statistical Testing Parameters</summary>

            - **Sample size:** 50 iterations per benchmark
            - **Significance level (Œ±):** 0.05
            - **Effect threshold:** ‚â•2.0% change required
            - **Test:** Welch's t-test (two-tailed)

            </details>

            <sub>Run via bench-compare on ubuntu-latest with Rust nightly-2026-01-05</sub>
          edit-mode: replace

      - name: Fail on regressions
        if: steps.bench-compare.outputs.exit_code == '1'
        run: |
          echo "::error::Benchmark regressions detected. See the HTML report for details."
          exit 1
